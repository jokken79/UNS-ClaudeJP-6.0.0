# üöÄ PLAN DE EJECUCI√ìN 8 SEMANAS - UNS-ClaudeJP 6.0.0

**Objetivo:** Transformar el proyecto de estado actual (6.5/10) a LISTO PRODUCCI√ìN (9/10)

**Estimado:** 132 horas = 4 semanas fulltime / 8 semanas part-time
**Rama:** `claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM`
**Fecha inicio:** 2025-11-19

---

## üìã TABLA DE CONTENIDOS

1. [SEMANA 1: Bugs Cr√≠ticos](#semana-1)
2. [SEMANA 2: Migraciones](#semana-2)
3. [SEMANA 3-4: Limpieza C√≥digo](#semana-3-4)
4. [SEMANA 5: Documentaci√≥n](#semana-5)
5. [SEMANA 6: Testing](#semana-6)
6. [SEMANA 7: Performance](#semana-7)
7. [SEMANA 8: QA y Release](#semana-8)
8. [Checkpoints y Validation](#checkpoints)

---

## <a name="semana-1"></a>üî¥ SEMANA 1: BUGS CR√çTICOS (Instalaci√≥n)

**Objetivo:** Sistema funciona al instalar desde cero
**Estimado:** 12 horas
**Riesgo:** BAJO

### Lunes: Corregir dependencias y environment

#### Tarea 1.1: Corregir pyodbc (Windows-only)
**Ubicaci√≥n:** `backend/requirements.txt:31`
**Problema:** `pyodbc==5.3.0` falla en Docker Linux
**Soluci√≥n:**

```bash
# 1. Editar requirements.txt
# Cambiar l√≠nea 31 de:
pyodbc==5.3.0

# A:
pyodbc==5.3.0; sys_platform == 'win32'
```

**Validaci√≥n:**
```bash
docker compose build backend  # Debe completar sin errores
```

**Tiempo:** 15 min
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 1.2: Generar SECRET_KEY √∫nico
**Ubicaci√≥n:** `scripts/setup/generate_env.py`
**Problema:** SECRET_KEY no es √∫nico (seguridad comprometida)
**Soluci√≥n:**

```python
# backend/.env.example l√≠nea 16
# Cambiar:
SECRET_KEY=change-me-to-a-64-byte-token

# A:
SECRET_KEY=<GENERADO_AUTOM√ÅTICAMENTE>

# En scripts/setup/generate_env.py, agregar:
import secrets
SECRET_KEY = secrets.token_hex(32)  # 64 caracteres aleatorios
```

**Validaci√≥n:**
```bash
python scripts/setup/generate_env.py
grep "SECRET_KEY=" .env  # Debe mostrar token de 64 caracteres
```

**Tiempo:** 30 min
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 1.3: Corregir NEXT_PUBLIC_API_URL
**Ubicaci√≥n:** `frontend/.env.example:189`
**Problema:** `NEXT_PUBLIC_API_URL=http://localhost:8000/api` ‚Üí timeout en Docker
**Soluci√≥n:**

```bash
# Cambiar:
NEXT_PUBLIC_API_URL=http://localhost:8000/api

# A (relativo, permite nginx routing):
NEXT_PUBLIC_API_URL=/api
```

**Validaci√≥n:**
```bash
# En frontend/lib/api.ts, verificar que usa NEXT_PUBLIC_API_URL correctamente
grep -n "NEXT_PUBLIC_API_URL" frontend/lib/api.ts
```

**Tiempo:** 15 min
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 1.4: Versi√≥n v6.0.0 en todo el c√≥digo
**Problema:** C√≥digo menciona v5.6.0, repo es v6.0.0
**Archivos a actualizar:**

1. **backend/app/core/config.py**
```python
# L√≠nea ~16, cambiar:
APP_VERSION: str = "5.6.0"
# A:
APP_VERSION: str = "6.0.0"
```

2. **backend/tests/conftest.py**
```python
# L√≠nea ~17, cambiar:
"APP_VERSION", os.getenv("APP_VERSION", "5.6.0")
# A:
"APP_VERSION", os.getenv("APP_VERSION", "6.0.0")
```

3. **README.md**
```markdown
# Cambiar badges en l√≠neas 1-10:
![Version](https://img.shields.io/badge/version-5.6.0-blue.svg)
# A:
![Version](https://img.shields.io/badge/version-6.0.0-blue.svg)
```

4. **docker-compose.yml**
```yaml
# Verificar nombre y referencias:
name: uns-claudejp-600  # OK
# Verificar todos los services usan latest compatible versions
```

**Validaci√≥n:**
```bash
grep -r "5\.6\.0\|5\.4\." backend/ frontend/ README.md | grep -v archive | wc -l
# Debe mostrar 0 l√≠neas (excepto en archive/)
```

**Tiempo:** 1 hora
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 1.5: Crear BASEDATEJP si no existe
**Ubicaci√≥n:** `docker-compose.yml:112`
**Problema:** Docker compose monta BASEDATEJP pero no existe

```bash
# Crear directorio
mkdir -p ./BASEDATEJP
# Crear .gitkeep para que git lo trackee
touch ./BASEDATEJP/.gitkeep
```

**Tiempo:** 5 min
**Prioridad:** üü† ALTA

---

### Martes: Testing b√°sico

#### Tarea 1.6: Instalar y ejecutar desde cero
```bash
# 1. Limpiar (si es desarrollo local)
docker compose down -v  # -v elimina vol√∫menes
rm .env  # Fuerza regeneraci√≥n

# 2. Generar .env
python scripts/setup/generate_env.py

# 3. Iniciar servicios
docker compose up -d

# 4. Esperar 30s para que servicios levanten
sleep 30

# 5. Verificar salud
docker compose ps  # Todos deben estar en "running"
curl http://localhost:8000/api/health  # Debe responder 200
curl http://localhost:3000  # Debe servir HTML
```

**Validaci√≥n Checklist:**
- [ ] `docker compose ps` muestra todos en "Up"
- [ ] `curl http://localhost:8000/api/health` ‚Üí {"status": "ok"}
- [ ] Frontend carga en http://localhost:3000
- [ ] Login funciona con admin/admin123
- [ ] Puedo hacer GET /api/candidates (debe retornar 200)

**Tiempo:** 1 hora (incluyendo troubleshooting)
**Prioridad:** üî¥ CR√çTICA

---

### Mi√©rcoles-Jueves: Documentaci√≥n inicial

#### Tarea 1.7: Actualizar README.md
**Ubicaci√≥n:** `/README.md`

**Cambios requeridos:**
- Actualizar versi√≥n 5.6.0 ‚Üí 6.0.0 (todos los badges)
- Actualizar enlace del repo (si cambi√≥)
- Verificar URLs funcionan
- Agregar secci√≥n "CAMBIOS EN v6.0.0"

**Tiempo:** 1 hora
**Prioridad:** üü† ALTA

---

#### Tarea 1.8: Crear CHANGELOG_V6.0.0.md
**Ubicaci√≥n:** `/CHANGELOG_V6.0.0.md`

**Contenido:**
```markdown
# Changelog v6.0.0

## üéØ Cambios Principales

### ‚úÖ Corregido
- Instalaci√≥n desde cero ahora funciona sin errores
- pyodbc condicional (Windows-only)
- SECRET_KEY generado √∫nicamente en cada instalaci√≥n
- NEXT_PUBLIC_API_URL optimizado para nginx routing
- Versiones sincronizadas en todo el c√≥digo

### üì¶ Dependencias
- Backend: 94 paquetes (1 cr√≠tico corregido: pyodbc)
- Frontend: 81 paquetes (todas compatibles)

### üìù Documentaci√≥n
- README.md actualizado a v6.0.0
- Gu√≠a de instalaci√≥n limpia
- Troubleshooting de bugs conocidos

### ‚è±Ô∏è Timeline
- Fase 1 (SEMANA 1): Bugs cr√≠ticos ‚úÖ
- Fase 2 (SEMANA 2): Migraciones üîÑ
- Fase 3-4 (SEMANA 3-4): Limpieza c√≥digo üìÖ
- Fase 5 (SEMANA 5): Documentaci√≥n üìÖ
- Fase 6 (SEMANA 6): Testing üìÖ
- Fase 7 (SEMANA 7): Performance üìÖ
- Fase 8 (SEMANA 8): Release üìÖ
```

**Tiempo:** 30 min
**Prioridad:** üü° MEDIA

---

#### Tarea 1.9: Crear INSTALACION_RAPIDA.md
**Ubicaci√≥n:** `/INSTALACION_RAPIDA.md`

```markdown
# Instalaci√≥n R√°pida v6.0.0

## Requisitos
- Docker Desktop (Windows/Mac) o Docker Engine (Linux)
- Python 3.11+
- 4GB RAM m√≠nimo
- Puertos: 3000, 8000, 5432, 8080, 6379

## Pasos

### 1. Clonar y preparar
bash
git clone https://github.com/jokken79/UNS-ClaudeJP-6.0.0.git
cd UNS-ClaudeJP-6.0.0
python scripts/setup/generate_env.py


### 2. Iniciar servicios
bash
docker compose up -d
docker compose ps  # Verificar todos "Up"


### 3. Esperar y validar
bash
sleep 30
curl http://localhost:8000/api/health
# Debe responder: {"status": "ok"}


### 4. Acceder
- Frontend: http://localhost:3000
- Backend API: http://localhost/api
- Swagger docs: http://localhost:8000/api/docs
- Database UI: http://localhost:8080

### 5. Login
- Usuario: admin
- Contrase√±a: admin123

## Troubleshooting

### ERROR: "Could not build wheels for pyodbc"
- Significa est√°s en Linux. Esto est√° corregido en v6.0.0.
- Si a√∫n ocurre: Actualiza requirements.txt

### ERROR: "Connection refused" en frontend
- Frontend no puede conectar a backend.
- Verificar: curl http://localhost/api/health
- Si falla: docker compose logs nginx

### ERROR: "403 Forbidden" en login
- SECRET_KEY no sincronizado entre servicios.
- Soluci√≥n: docker compose restart backend frontend

## Detener servicios
bash
docker compose down

## Limpiar completamente
bash
docker compose down -v  # Elimina vol√∫menes de datos
rm .env
python scripts/setup/generate_env.py
docker compose up -d  # Fresh start
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

### Viernes: Validaci√≥n y commit

#### Tarea 1.10: Validar suite completa SEMANA 1
```bash
# Checklist final
[ ] docker compose up -d (sin errores)
[ ] docker compose ps (todos "Up")
[ ] curl http://localhost:8000/api/health (200 OK)
[ ] Acceder a http://localhost:3000 (carga)
[ ] Login admin/admin123 (funciona)
[ ] GET /api/candidates (retorna datos)
[ ] Versiones consistentes (v6.0.0)
[ ] README.md actualizado
[ ] CHANGELOG_V6.0.0.md creado
[ ] INSTALACION_RAPIDA.md creado
```

**Tiempo:** 1 hora
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 1.11: Commit SEMANA 1
```bash
git add -A
git commit -m "SEMANA 1: Corregir bugs cr√≠ticos de instalaci√≥n v6.0.0

- Corregir pyodbc como dependencia condicional Windows-only
- Implementar generaci√≥n √∫nica de SECRET_KEY
- Cambiar NEXT_PUBLIC_API_URL a relativo para nginx routing
- Sincronizar versi√≥n a v6.0.0 en todo el c√≥digo
- Crear directorio BASEDATEJP
- Agregar documentaci√≥n: README.md, CHANGELOG_V6.0.0.md, INSTALACION_RAPIDA.md

Sistema ahora instala desde cero sin errores.
Validado: ‚úÖ docker compose up, ‚úÖ login, ‚úÖ API calls
"

git push -u origin claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM
```

**Tiempo:** 15 min
**Prioridad:** üî¥ CR√çTICA

---

**üìä SEMANA 1 RESUMEN:**
- ‚è±Ô∏è Estimado: 12 horas
- ‚úÖ Sistema instala desde cero
- ‚úÖ Login funciona
- ‚úÖ APIs responden
- üìù Documentaci√≥n inicial lista
- üéØ Siguiente: SEMANA 2 - Migraciones

---

## <a name="semana-2"></a>üü† SEMANA 2: MIGRACIONES (Schema consistency)

**Objetivo:** Resolver 15 migraciones deshabilitadas
**Estimado:** 16 horas
**Riesgo:** MEDIO

### Lunes: Auditar migraciones deshabilitadas

#### Tarea 2.1: Listar todas las migraciones
```bash
cd backend
ls -lah alembic/versions/ | grep -E "\.(DISABLED|disabled|py\.old)"

# Resultado esperado: 15 migraciones deshabilitadas
# Ejemplo:
# 002_add_housing_subsidy_field.py.DISABLED
# 003_add_nyuusha_renrakuhyo_fields.py.disabled
# ... (13 m√°s)
```

**Crear archivo:** `/MIGRATIONS_AUDIT.txt`

Para cada migraci√≥n deshabilitada, documentar:
1. Nombre
2. Fecha creaci√≥n (estimada)
3. Campos que agrega
4. Raz√≥n por la que fue deshabilitada
5. Decisi√≥n: APLICAR / ELIMINAR

**Tiempo:** 2 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 2.2: An√°lisis de riesgo por migraci√≥n
```python
# backend/scripts/analyze_migrations.py (crear nuevo script)
import os
import re
from pathlib import Path

def analyze_disabled_migrations():
    """
    Analizar todas las migraciones deshabilitadas y listar:
    - Campos que definen
    - Si esos campos est√°n en models.py
    - Si est√°n en BD
    """
    disabled_migrations = Path("alembic/versions").glob("*.DISABLED")
    disabled_migrations += Path("alembic/versions").glob("*.disabled")

    for migration_file in disabled_migrations:
        with open(migration_file) as f:
            content = f.read()
            # Buscar ADD COLUMN, CREATE TABLE, etc.
            print(f"\n{migration_file.name}")
            # Extraer operaciones
            # Verificar si est√°n en models.py
            # Reportar inconsistencias

if __name__ == "__main__":
    analyze_disabled_migrations()
```

**Ejecutar:**
```bash
cd backend
python scripts/analyze_migrations.py > /tmp/migrations_analysis.txt
```

**Tiempo:** 3 horas
**Prioridad:** üî¥ CR√çTICA

---

### Martes-Mi√©rcoles: Tomar decisiones

#### Tarea 2.3: Revisar cada migraci√≥n y decidir

**Decisi√≥n para cada migraci√≥n:**

**OPCI√ìN A: APLICAR (si necesaria)**
- Los campos est√°n en models.py
- Vamos a usar esa funcionalidad
- Ejemplo: `add_ai_budget_table.py` (nueva funcionalidad)

**Opci√≥n B: ELIMINAR (si obsoleta)**
- Los campos est√°n viejos
- Ya no se usan
- Ejemplo: `add_parking_field.py` (reemplazado por v2)

**Opci√≥n C: REVISAR (si incierta)**
- Requiere an√°lisis m√°s profundo
- Pasar a reuni√≥n con stakeholders

**Crear archivo de decisiones:** `/MIGRATIONS_DECISIONS.md`

```markdown
# Decisiones Migraciones

## APLICAR (5 migraciones)
- [ ] 2025_11_16_add_ai_budget_table.py ‚Üí APLICAR (nueva funcionalidad)
- [ ] 2025_11_16_add_ai_usage_log_table.py ‚Üí APLICAR (nueva funcionalidad)
- [ ] 2025_11_12_1804_add_parking_and_plus_fields.py ‚Üí APLICAR
- [ ] 2025_11_12_1900_add_tax_rates_to_payroll_settings.py ‚Üí APLICAR
- [ ] 2025_11_12_1900_add_timer_cards_indexes_constraints.py ‚Üí APLICAR

## ELIMINAR (7 migraciones)
- [ ] 002_add_housing_subsidy_field.py.DISABLED ‚Üí ELIMINAR (duplica v2)
- [ ] 003_add_nyuusha_renrakuhyo_fields.py.disabled ‚Üí ELIMINAR (viejo)
- [ ] 43b6cf501eed_add_pays_parking_field_to_apartment_assignments.py.DISABLED ‚Üí ELIMINAR (consolidado)
- [ ] 5e6575b9bf1b_add_apartment_system_v2_assignments_charges_deductions.py.DISABLED ‚Üí APLICAR o ELIMINAR (cr√≠tico)
- [ ] 642bced75435_add_property_type_field_to_apartments.py.DISABLED ‚Üí REVISAR
- [ ] 68534af764e0_add_additional_charges_and_rent_deductions_tables.py.DISABLED ‚Üí REVISAR
- [ ] 2025_11_12_2100_add_admin_audit_log_table.py.DISABLED ‚Üí REVISAR

## REVISAR (3 migraciones)
- [ ] 2025_11_12_1900_add_timer_cards_indexes_constraints.py.DISABLED ‚Üí Requiere an√°lisis
- [ ] 2025_11_12_2000_remove_redundant_employee_id_from_timer_cards.py.DISABLED ‚Üí Puede romper datos
- [ ] 2025_11_12_2200_add_additional_search_indexes.py.DISABLED ‚Üí Performance
```

**Tiempo:** 6 horas (incluir reuni√≥n si necesario)
**Prioridad:** üî¥ CR√çTICA

---

### Jueves: Aplicar migraciones decididas

#### Tarea 2.4: Renombrar migraciones a aplicar
```bash
cd backend/alembic/versions/

# Renombrar archivos .DISABLED ‚Üí .py (para aplicarlas)
for f in *.DISABLED; do mv "$f" "${f%.DISABLED}"; done
for f in *.disabled; do mv "$f" "${f%.disabled}"; done

# Eliminar las que decidimos descartar
rm -f 002_add_housing_subsidy_field.py
rm -f 003_add_nyuusha_renrakuhyo_fields.py
# ... (eliminar las 7 que decidimos)
```

**Validaci√≥n:**
```bash
ls -la alembic/versions/*.py | wc -l
# Debe mostrar: n√∫mero_original - 7 (eliminadas)
```

**Tiempo:** 30 min
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 2.5: Ejecutar migraciones
```bash
cd backend

# 1. Backup BD (importante!)
docker exec uns-claudejp-db pg_dump -U uns_admin uns_claudejp > \
  /tmp/backup_before_migrations_$(date +%Y%m%d_%H%M%S).sql

# 2. Aplicar migraciones
docker exec uns-claudejp-backend bash -c "cd /app && alembic upgrade head"

# 3. Verificar resultado
docker exec uns-claudejp-db psql -U uns_admin -d uns_claudejp -c "\dt" | head -20
# Debe mostrar nuevas tablas
```

**Validaci√≥n:**
```bash
# Verificar migraciones aplicadas
docker exec uns-claudejp-backend bash -c "cd /app && alembic current"
docker exec uns-claudejp-backend bash -c "cd /app && alembic history | head -10"

# Verificar schema matches models.py
python backend/scripts/verify_schema_consistency.py
```

**Tiempo:** 1 hora
**Prioridad:** üî¥ CR√çTICA

---

### Viernes: Validaci√≥n y commit

#### Tarea 2.6: Validar integridad de datos
```bash
# 1. Verificar no hay errores en logs
docker compose logs backend | grep -i error | head -20

# 2. Verificar API a√∫n funciona
curl http://localhost:8000/api/health

# 3. Correr tests
docker exec uns-claudejp-backend pytest tests/test_health.py -v

# 4. Verificar datos persistieron
curl http://localhost:8000/api/candidates | jq '.count'
# Debe mostrar n√∫mero > 0 (si hay datos)
```

**Checklist:**
- [ ] Migraciones aplicadas sin errores
- [ ] BD schema matches models.py
- [ ] API funciona
- [ ] Datos persistieron
- [ ] Tests pasan

**Tiempo:** 1 hora
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 2.7: Commit SEMANA 2
```bash
git add -A
git commit -m "SEMANA 2: Resolver 15 migraciones deshabilitadas

- Auditor√≠a completa de migraciones .DISABLED
- Documento de decisiones para cada migraci√≥n
- Aplicar 8 migraciones necesarias
- Eliminar 7 migraciones obsoletas
- Validar schema BD vs models.py
- Crear backup y rollback plan

Sistema ahora tiene schema consistente.
Validado: ‚úÖ alembic upgrade head, ‚úÖ API funciona, ‚úÖ Datos persisten
"

git push -u origin claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM
```

**Tiempo:** 15 min

---

**üìä SEMANA 2 RESUMEN:**
- ‚è±Ô∏è Estimado: 16 horas
- ‚úÖ 15 migraciones resueltas (8 aplicadas, 7 eliminadas)
- ‚úÖ Schema BD consistente con models.py
- ‚úÖ Datos validados
- üìù Decisiones documentadas
- üéØ Siguiente: SEMANA 3-4 - Limpieza de c√≥digo

---

## <a name="semana-3-4"></a>üí™ SEMANA 3-4: LIMPIEZA DE C√ìDIGO (Dead code elimination)

**Objetivo:** Reducir de 305 ‚Üí 220 archivos Python (28% reducci√≥n)
**Estimado:** 40 horas
**Riesgo:** MEDIO-ALTO

### Semana 3: Limpieza de directorios y scripts

#### Tarea 3.1: Eliminar 7 directorios orphaned

**Directorios a eliminar:**
1. `backend/cache/` (850 l√≠neas, duplica cache_service.py)
2. `backend/extractors/` (800+ l√≠neas, duplica photo_service.py)
3. `backend/processors/` (600+ l√≠neas, duplica batch_optimizer.py)
4. `backend/validation/` (800+ l√≠neas, nunca se usa)
5. `backend/config/` (debe estar en app/core/)
6. `backend/performance/` (nunca se usa)
7. `backend/utils/` (duplica app/core/logging.py)

**Pasos:**

```bash
cd backend

# 1. Verificar qu√© scripts dependen de estos directorios
grep -r "from cache import\|from extractors import\|from processors import\|from validation import\|from config import\|from performance import\|from utils import" . --include="*.py" | head -20

# 2. Buscar si alg√∫n script .py los importa
grep -r "from backend.cache\|from backend.extractors\|from backend.processors" scripts/ --include="*.py"

# 3. Si no hay dependencias, eliminar
rm -rf cache/ extractors/ processors/ validation/ config/ performance/ utils/

# 4. Verificar no rompi√≥ nada
git status | grep "deleted\|modified"
```

**Validaci√≥n:**
```bash
# Tests deben pasar
pytest tests/ -v --tb=short | tail -20
# Si falla alg√∫n test, fue por dependencia no detectada
```

**Tiempo:** 4 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 3.2: Consolidar scripts de foto (29 scripts ‚Üí 1)

**Scripts a consolidar:**
```
backend/scripts/
‚îú‚îÄ auto_extract_photos_from_databasejp.py
‚îú‚îÄ auto_extract_photos_from_databasejp_v2.py
‚îú‚îÄ extract_photos_from_access_db_v52.py
‚îú‚îÄ extract_all_photos_urgente.py
‚îî‚îÄ ... (25 m√°s)
```

**Estrategia:**

```bash
cd backend/scripts

# 1. Identificar la MEJOR versi√≥n
# (normalmente la m√°s nueva o la que m√°s tests tiene)
ls -lt extract_photos*.py | head -3
# Ejemplo: extract_photos_v2_improved.py es la mejor

# 2. Renombrar la mejor a nombre est√°ndar
mv extract_photos_v2_improved.py extract_photos.py

# 3. Crear alias para scripts que llamen la anterior
cat > extract_photos_legacy.py << 'EOF'
#!/usr/bin/env python3
"""Legacy alias para extract_photos.py"""
from extract_photos import main

if __name__ == "__main__":
    main()
EOF

# 4. Eliminar versiones viejas
for f in auto_extract_photos_*.py extract_photos_v1*.py extract_photos_v2*.py; do
    [ -f "$f" ] && [ "$f" != "extract_photos.py" ] && rm "$f"
done

# 5. Verificar solo quedan 1-2 versiones
ls extract_photos*.py
# Resultado esperado: extract_photos.py, extract_photos_legacy.py
```

**Crear documentaci√≥n:**
```markdown
# backend/scripts/EXTRACT_PHOTOS_README.md

## Consolidaci√≥n de scripts de extracci√≥n de fotos

De 29 scripts, consolidados a:
- `extract_photos.py` - VERSI√ìN PRINCIPAL (reemplaza todas)
- `extract_photos_legacy.py` - ALIAS para compatibilidad

### Uso:
python extract_photos.py

### Scripts antiguos:
Todos los scripts v1, v2, v3, etc. han sido ELIMINADOS.
Si necesitas la versi√≥n anterior, usar: git log --follow scripts/extract_photos.py
```

**Tiempo:** 6 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 3.3: Consolidar scripts de admin (10 scripts ‚Üí 1)

**Scripts a consolidar:**
```
create_admin_user.py
reset_admin_simple.py
reset_admin_password.py
reset_admin_now.py
fix_admin_password.py
... (5 m√°s)
```

**Estrategia:**

```bash
# 1. Identificar el mejor
ls -lt *admin*.py | head -3

# 2. Usar como principal
mv create_admin_user_best.py create_admin_user.py

# 3. Crear aliases
cat > reset_admin.py << 'EOF'
#!/usr/bin/env python3
"""Alias para create_admin_user.py"""
from create_admin_user import reset_admin

if __name__ == "__main__":
    reset_admin()
EOF

# 4. Eliminar el resto
for f in reset_admin*.py fix_admin*.py; do
    [ -f "$f" ] && [ "$f" != "create_admin_user.py" ] && rm "$f"
done
```

**Resultado:**
- `create_admin_user.py` (principal)
- `reset_admin.py` (alias)

**Tiempo:** 4 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 3.4: Consolidar scripts de import (19 scripts ‚Üí 3)

**Consolidaci√≥n:**
```
import_candidates_simple.py      ‚Üí ELIMINAR (viejo)
import_candidates_improved.py    ‚Üí MANTENER (mejor)
import_candidates_robust.py      ‚Üí ELIMINAR (viejo)
resilient_importer.py            ‚Üí MANTENER (alternativa)
import_employees_from_excel.py   ‚Üí MANTENER (especializado)
```

**Crear matriz:**
```markdown
# backend/scripts/IMPORT_SCRIPTS_MATRIX.md

## Matriz de decisiones

| Script | Prop√≥sito | Decisi√≥n | Reemplazo |
|--------|-----------|----------|-----------|
| import_candidates_simple.py | Importar b√°sico | ELIMINAR | import_candidates_improved.py |
| import_candidates_improved.py | Mejor importador | MANTENER | - |
| import_candidates_robust.py | Viejo robusto | ELIMINAR | resilient_importer.py |
| resilient_importer.py | Importador con retry | MANTENER | - |
| import_employees_from_excel.py | Empleados | MANTENER | - |
| ... 14 m√°s | | | |
```

**Resultado:**
- `import_candidates_improved.py` (principal)
- `resilient_importer.py` (alternativa)
- `import_employees_from_excel.py` (especializado)

**Tiempo:** 4 horas
**Prioridad:** üü† ALTA

---

#### Tarea 3.5: Crear manifest de scripts esenciales

**Archivo:** `backend/scripts/ESSENTIAL_SCRIPTS.md`

```markdown
# Scripts Esenciales

## Cr√≠ticos (SIEMPRE ejecutar al setup)
- [ ] manage_db.py - Gestor principal de BD
- [ ] create_admin_user.py - Crear usuario admin

## Importantes (Data management)
- [ ] import_candidates_improved.py - Importar candidatos
- [ ] resilient_importer.py - Importar con retry
- [ ] import_employees_from_excel.py - Importar empleados
- [ ] extract_photos.py - Extraer fotos

## Utilitarios (Maintenance)
- [ ] verify_data.py - Verificar integridad
- [ ] sync_candidate_employee_status.py - Sincronizar datos
- [ ] export_to_json.py - Exportar datos

## Testing (Development)
- [ ] test_ocr_pipeline.py - Test OCR
- [ ] test_db_connection.py - Test BD

## Total: 12 scripts esenciales (de 96 originales)
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

### Semana 4: Consolidar servicios duplicados

#### Tarea 4.1: Consolidar servicios de Payroll (7 ‚Üí 1)

**Archivos duplicados:**
```
backend/app/services/
‚îú‚îÄ payroll_service.py
‚îú‚îÄ payroll/payroll_service.py (duplicado)
‚îú‚îÄ payroll_integration_service.py
‚îú‚îÄ payslip_service.py
‚îú‚îÄ salary_service.py
‚îú‚îÄ salary_export_service.py
‚îî‚îÄ deduction_service.py
```

**Estrategia:**

1. **Analizar cada archivo** (l√≠nea por l√≠nea)
```bash
cd backend/app/services/

# Ver tama√±o y contenido
wc -l payroll*.py salary*.py deduction*.py
cat payroll_service.py | head -50  # Ver qu√© hace
```

2. **Consolidar en UNO:** `payroll_service.py`
```python
# backend/app/services/payroll_service.py (nuevo, consolidado)

class PayrollService:
    """Servicio consolidado de n√≥mina"""

    async def calculate_payroll(self, employee_id):
        """Calcula n√≥mina (reemplaza payroll_integration_service)"""
        pass

    async def generate_payslip(self, payroll_id):
        """Genera n√≥mina (reemplaza payslip_service)"""
        pass

    async def apply_deductions(self, payroll_id):
        """Aplica deducciones (reemplaza deduction_service)"""
        pass

    async def export_payroll(self, payroll_id, format='pdf'):
        """Exporta n√≥mina (reemplaza salary_export_service)"""
        pass
```

3. **Eliminar archivos duplicados**
```bash
rm -f payroll/payroll_service.py
rm -f payroll_integration_service.py
rm -f payslip_service.py
rm -f salary_service.py  # O si es diferente, consolidar
rm -f salary_export_service.py
rm -f deduction_service.py
```

4. **Actualizar imports en routers**
```bash
# Buscar qu√© routers importan estos servicios
grep -r "from.*payroll_service\|from.*payslip_service\|from.*deduction" ../api/ --include="*.py"

# Cambiar imports a usar payroll_service.py consolidado
# Ejemplo: from payroll_service import PayrollService
```

5. **Validar tests pasan**
```bash
pytest tests/test_payroll*.py -v
```

**Tiempo:** 8 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 4.2: Consolidar servicios de OCR (7 ‚Üí 1)

**Archivos:**
```
backend/app/services/
‚îú‚îÄ azure_ocr_service.py
‚îú‚îÄ easyocr_service.py
‚îú‚îÄ tesseract_ocr_service.py
‚îú‚îÄ hybrid_ocr_service.py
‚îú‚îÄ timer_card_ocr_service.py
‚îú‚îÄ ocr_cache_service.py
‚îî‚îÄ ocr_weighting.py
```

**Estrategia similar a payroll:**

1. `hybrid_ocr_service.py` es el "maestro" (ya combina los dem√°s)
2. Mover todo a `hybrid_ocr_service.py`
3. Eliminar duplicados

**Tiempo:** 6 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 4.3: Consolidar servicios de Caching (3 ‚Üí 1)

**Archivos:**
```
cache_service.py
ocr_cache_service.py (OCR espec√≠fico)
backend/cache/photo_cache.py (nunca usado)
```

**Estrategia:**
1. Mantener `cache_service.py` (general)
2. Integrar OCR caching como m√©todo
3. Eliminar `ocr_cache_service.py` y `backend/cache/`

**Tiempo:** 2 horas
**Prioridad:** üü° MEDIA

---

#### Tarea 4.4: Consolidar servicios de Apartments (4 ‚Üí 1)

**Schemas duplicados:**
```
apartment.py (v1)
apartment_factory.py
apartment_v2.py
apartment_v2_complete.py
```

**Estrategia:**
1. Usar `apartment_v2_complete.py` como base
2. Consolidar todos los campos
3. Mantener solo UNO

**Tiempo:** 4 horas
**Prioridad:** üü° MEDIA

---

#### Tarea 4.5: Validaci√≥n general

```bash
# 1. Contar servicios antes/despu√©s
find backend/app/services -name "*.py" | wc -l
# Antes: ~38, Despu√©s: ~20

# 2. Verificar imports
cd backend
python -m py_compile app/services/*.py  # Debe compilar sin errores

# 3. Correr tests
pytest tests/test_payroll*.py tests/test_ocr*.py tests/test_apartment*.py -v
```

**Tiempo:** 2 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 4.6: Commit SEMANA 3-4

```bash
git add -A
git commit -m "SEMANA 3-4: Consolidar 96 scripts y 38 servicios

Limpieza de c√≥digo muerto:
- Eliminar 7 directorios orphaned (3,500 l√≠neas)
- Consolidar 29 scripts foto ‚Üí 1
- Consolidar 10 scripts admin ‚Üí 1
- Consolidar 19 scripts import ‚Üí 3
- Resultado: 96 scripts ‚Üí 12 esenciales

Consolidar servicios duplicados:
- Payroll: 7 ‚Üí 1 (PayrollService)
- OCR: 7 ‚Üí 1 (HybridOCRService)
- Caching: 3 ‚Üí 1 (CacheService)
- Apartments: 4 ‚Üí 1 (ApartmentService)
- Resultado: 38 servicios ‚Üí ~20

Total reducci√≥n:
- De 305 archivos Python ‚Üí ~210 (31% reducci√≥n)
- De 98,854 l√≠neas ‚Üí ~70,000 (29% reducci√≥n)
- Mantenibilidad mejorada: 40-50%

Validado: ‚úÖ Tests pasan, ‚úÖ API funciona, ‚úÖ Imports resueltos
"

git push -u origin claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM
```

---

**üìä SEMANA 3-4 RESUMEN:**
- ‚è±Ô∏è Estimado: 40 horas
- ‚úÖ De 305 ‚Üí 210 archivos Python (31% reducci√≥n)
- ‚úÖ De 98,854 ‚Üí 70,000 l√≠neas (29% reducci√≥n)
- ‚úÖ C√≥digo consolidado y organizado
- üéØ Siguiente: SEMANA 5 - Documentaci√≥n

---

## <a name="semana-5"></a>üìö SEMANA 5: DOCUMENTACI√ìN (Organize chaos)

**Objetivo:** De 606 ‚Üí <100 archivos .md bien organizados
**Estimado:** 24 horas
**Riesgo:** BAJO

### Lunes: Auditor√≠a completa

#### Tarea 5.1: Listar y categorizar 606 archivos .md

```bash
# 1. Contar
find /home/user/UNS-ClaudeJP-6.0.0 -name "*.md" | wc -l
# Resultado: ~606

# 2. Listar con tama√±o
find /home/user/UNS-ClaudeJP-6.0.0 -name "*.md" -exec ls -lh {} \; | \
  awk '{print $5, $NF}' | sort -k2 > /tmp/md_files.txt

# 3. Agrupar por categor√≠a
grep "ra√≠z:" /tmp/md_files.txt | wc -l   # Archivos en ra√≠z
grep "docs/" /tmp/md_files.txt | wc -l   # Archivos en docs/
grep "archive" /tmp/md_files.txt | wc -l # Archivos en archive
```

**Crear matriz:** `/DOCUMENTACION_AUDIT.md`

```markdown
# Auditor√≠a de Documentaci√≥n

## Resumen
- Total archivos .md: 606
- Ra√≠z: 239 (ca√≥tico)
- docs/: 367 (mejor)
- Duplicados: ~50 (estimado)
- Obsoletos: ~40 (estimado)

## Ra√≠z (239 archivos)
Deben quedarse (5):
- [ ] README.md
- [ ] CLAUDE.md
- [ ] CHANGELOG_V6.0.0.md
- [ ] INSTALACION_RAPIDA.md
- [ ] CURSORRULES.md

Mover a docs/ (234):
- [ ] AUDIT_*.md (5) ‚Üí docs/archive/
- [ ] THEME_*.md (6) ‚Üí docs/features/themes/
- [ ] GUIA_COMPLETA_ESTILOS_TEMAS_DISENO.md ‚Üí docs/guides/styling.md
- [ ] MAPEO_RUTAS.md ‚Üí docs/architecture/routing.md
- [ ] ... (217 m√°s)

Eliminar (0):
- Nada, todo tiene informaci√≥n valiosa

## docs/ (367 archivos)
Reorganizar:
- docs/02-guides/ ‚Üí docs/guides/ (eliminar n√∫mero)
- docs/04-troubleshooting/ ‚Üí docs/troubleshooting/ (eliminar n√∫mero)
- docs/06-archive/ ‚Üí docs/archive/ (eliminar n√∫mero + duplica archive/)
- Crear docs/api/ si no existe
```

**Tiempo:** 3 horas
**Prioridad:** üü° MEDIA

---

### Martes: Reorganizar directorios

#### Tarea 5.2: Crear estructura de docs/ est√°ndar

```bash
cd /home/user/UNS-ClaudeJP-6.0.0/docs

# Crear estructura
mkdir -p {
  guides,
  architecture,
  api,
  features,
  troubleshooting,
  archive,
  research,
  security
}

# Renombrar si existen directorios con n√∫meros
[ -d "02-guides" ] && mv 02-guides/* guides/ 2>/dev/null
[ -d "04-troubleshooting" ] && mv 04-troubleshooting/* troubleshooting/ 2>/dev/null
[ -d "06-archive" ] && mv 06-archive/* archive/ 2>/dev/null && rmdir 06-archive
```

**Estructura final:**
```
docs/
‚îú‚îÄ README.md (√≠ndice de documentaci√≥n)
‚îú‚îÄ guides/
‚îÇ  ‚îú‚îÄ instalacion.md
‚îÇ  ‚îú‚îÄ desarrollo.md
‚îÇ  ‚îú‚îÄ testing.md
‚îÇ  ‚îú‚îÄ styling.md
‚îÇ  ‚îú‚îÄ troubleshooting.md
‚îÇ  ‚îî‚îÄ deployment.md
‚îú‚îÄ architecture/
‚îÇ  ‚îú‚îÄ backend.md
‚îÇ  ‚îú‚îÄ frontend.md
‚îÇ  ‚îú‚îÄ database.md
‚îÇ  ‚îî‚îÄ routing.md
‚îú‚îÄ features/
‚îÇ  ‚îú‚îÄ candidates.md
‚îÇ  ‚îú‚îÄ employees.md
‚îÇ  ‚îú‚îÄ payroll.md
‚îÇ  ‚îú‚îÄ timercards.md
‚îÇ  ‚îú‚îÄ apartments.md
‚îÇ  ‚îî‚îÄ themes.md
‚îú‚îÄ api/
‚îÇ  ‚îú‚îÄ endpoints.md
‚îÇ  ‚îî‚îÄ authentication.md
‚îú‚îÄ security/
‚îÇ  ‚îú‚îÄ secrets.md
‚îÇ  ‚îú‚îÄ cors.md
‚îÇ  ‚îî‚îÄ compliance.md
‚îú‚îÄ troubleshooting/
‚îÇ  ‚îú‚îÄ installation.md
‚îÇ  ‚îú‚îÄ common-errors.md
‚îÇ  ‚îî‚îÄ performance.md
‚îî‚îÄ archive/ (todo lo viejo)
```

**Tiempo:** 2 horas
**Prioridad:** üü† ALTA

---

#### Tarea 5.3: Mover archivos de ra√≠z a docs/

```bash
cd /home/user/UNS-ClaudeJP-6.0.0

# 1. MANTENER EN RA√çZ (5 √∫nicos)
MANTENER="README.md|CLAUDE.md|CHANGELOG_V6.0.0.md|INSTALACION_RAPIDA.md|CURSORRULES.md"

# 2. Mover AUDIT_*.md a archive
mv AUDIT_COMPLETE_ANALYSIS_2025-11-19.md docs/archive/
mv AUDIT_BUGS_REPORT_2025_11_16.md docs/archive/
mv AUDIT_SUMMARY_QUICK_REFERENCE.md docs/archive/

# 3. Mover THEME_*.md a features/themes
mv THEME_*.md docs/features/themes/ 2>/dev/null

# 4. Mover GUIA_COMPLETA_ESTILOS a guides
mv GUIA_COMPLETA_ESTILOS_TEMAS_DISENO.md docs/guides/styling.md

# 5. Mover CLEANUP_*.md a archive
mv CLEANUP_SUMMARY_*.md docs/archive/ 2>/dev/null

# 6. Mover CANDIDATOS_*.md a features
mv CANDIDATE_*.md docs/features/ 2>/dev/null

# 7. Mover EMPLOYEE_*.md a features
mv EMPLOYEE_*.md docs/features/ 2>/dev/null

# 8. Mover an√°lisis y reportes a archive
mv ANALYSIS_*.md docs/archive/ 2>/dev/null
mv REPORT_*.md docs/archive/ 2>/dev/null
mv DIAGNOSTIC_*.md docs/archive/ 2>/dev/null

# 9. Verificar qu√© qued√≥ en ra√≠z
ls *.md | grep -v -E "$MANTENER"
```

**Resultado esperado:**
```
/root/UNS-ClaudeJP-6.0.0/
‚îú‚îÄ README.md
‚îú‚îÄ CLAUDE.md
‚îú‚îÄ CHANGELOG_V6.0.0.md
‚îú‚îÄ INSTALACION_RAPIDA.md
‚îú‚îÄ CURSORRULES.md
‚îî‚îÄ docs/ (todo lo dem√°s)
```

**Tiempo:** 2 horas
**Prioridad:** üî¥ CR√çTICA

---

### Mi√©rcoles: Crear documentos maestros

#### Tarea 5.4: Crear docs/README.md (√≠ndice)

```markdown
# Documentaci√≥n UNS-ClaudeJP 6.0.0

## üìñ Gu√≠as de Inicio

- **[Instalaci√≥n R√°pida](../INSTALACION_RAPIDA.md)** - Instalar en 5 min
- **[Gu√≠a de Desarrollo](guides/desarrollo.md)** - Setup local
- **[Gu√≠a de Testing](guides/testing.md)** - Correr tests

## üèóÔ∏è Arquitectura

- **[Backend](architecture/backend.md)** - FastAPI, servicios, BD
- **[Frontend](architecture/frontend.md)** - Next.js, componentes
- **[Database](architecture/database.md)** - Schema, modelos
- **[Routing](architecture/routing.md)** - API endpoints

## üéØ Caracter√≠sticas

- **[Candidatos](features/candidates.md)** - Gesti√≥n de candidatos
- **[Empleados](features/employees.md)** - Gesti√≥n de empleados
- **[N√≥mina](features/payroll.md)** - C√°lculo autom√°tico
- **[Asistencia](features/timercards.md)** - Control de horas
- **[Vivienda](features/apartments.md)** - Housing system
- **[Temas](features/themes.md)** - Sistema de temas

## üîå API

- **[Endpoints](api/endpoints.md)** - Todas las rutas
- **[Autenticaci√≥n](api/authentication.md)** - JWT, roles

## üîê Seguridad

- **[Secrets y Configuraci√≥n](security/secrets.md)**
- **[CORS y Network](security/cors.md)**
- **[Compliance](security/compliance.md)**

## üõ†Ô∏è Troubleshooting

- **[Instalaci√≥n](troubleshooting/installation.md)**
- **[Errores Comunes](troubleshooting/common-errors.md)**
- **[Performance](troubleshooting/performance.md)**

## üìö Archive (Hist√≥rico)

- [Documentos Viejos](archive/) - v5.x y anteriores
- [Reportes Antiguos](archive/) - An√°lisis previos

## üìã Versiones

- **Actual:** 6.0.0
- **Changelog:** [CHANGELOG_V6.0.0.md](../CHANGELOG_V6.0.0.md)
```

**Tiempo:** 1 hora
**Prioridad:** üü† ALTA

---

#### Tarea 5.5: Crear guides/ principales

**Crear:** `docs/guides/desarrollo.md`
```markdown
# Gu√≠a de Desarrollo

## Setup Local

1. Generar .env: `python scripts/setup/generate_env.py`
2. Levantar servicios: `docker compose up -d`
3. Esperar 30s
4. Verificar: `curl http://localhost:8000/api/health`

## Desarrollo Backend

```bash
# Entrar al container
docker exec -it uns-claudejp-backend bash

# Modificar c√≥digo
vim app/api/candidates.py

# Tests autom√°ticos (hot reload activo)
pytest tests/ -v --tb=short
```

## Desarrollo Frontend

```bash
# Entrar al container
docker exec -it uns-claudejp-frontend bash

# Modificar c√≥digo
vim app/(dashboard)/candidates/page.tsx

# TypeScript validation
npm run typecheck

# Linting
npm run lint:fix
```

## Database Migrations

```bash
# Crear nueva migraci√≥n
docker exec uns-claudejp-backend bash -c "cd /app && alembic revision --autogenerate -m 'descripci√≥n'"

# Aplicar
docker exec uns-claudejp-backend bash -c "cd /app && alembic upgrade head"

# Ver hist√≥rico
docker exec uns-claudejp-backend bash -c "cd /app && alembic history"
```
```

**Crear:** `docs/guides/testing.md`
```markdown
# Gu√≠a de Testing

## Backend Tests

```bash
# Correr todos
pytest backend/tests/ -v

# Por m√≥dulo
pytest backend/tests/test_auth.py -v

# Con coverage
pytest backend/tests/ --cov=app --cov-report=html
```

## Frontend E2E Tests

```bash
# Correr todos
npm run test:e2e

# Con UI
npm run test:e2e:ui

# Specific test
npm run test:e2e:yukyu
```

## Coverage

- Backend: >70% coverage
- Frontend: E2E tests + manual
```

**Tiempo:** 3 horas
**Prioridad:** üü° MEDIA

---

### Jueves-Viernes: Validaci√≥n y limpieza final

#### Tarea 5.6: Verificar links en documentaci√≥n

```bash
# Crear script para verificar links
cat > /tmp/check_md_links.py << 'EOF'
import os
import re
from pathlib import Path

def check_links():
    """Verificar que todos los links en .md apunten a archivos reales"""
    errors = []

    for md_file in Path('/home/user/UNS-ClaudeJP-6.0.0').rglob('*.md'):
        with open(md_file) as f:
            content = f.read()

            # Buscar links [text](path)
            links = re.findall(r'\[.*?\]\((.*?)\)', content)

            for link in links:
                if link.startswith(('http://', 'https://', '#')):
                    continue  # Skip external links

                # Resolver ruta relativa
                if link.startswith('/'):
                    full_path = f"/home/user/UNS-ClaudeJP-6.0.0{link}"
                else:
                    full_path = (md_file.parent / link).resolve()

                if not full_path.exists():
                    errors.append(f"{md_file}: Link roto: {link}")

    return errors

if __name__ == "__main__":
    errors = check_links()
    if errors:
        print("ERRORES ENCONTRADOS:")
        for error in errors[:20]:  # Mostrar primeros 20
            print(f"  ‚ùå {error}")
    else:
        print("‚úÖ Todos los links est√°n bien!")
EOF

python /tmp/check_md_links.py
```

**Tiempo:** 2 horas
**Prioridad:** üü† ALTA

---

#### Tarea 5.7: Crear CONTRIBUTING.md

```markdown
# Contribuyendo al Proyecto

## Proceso

1. Clonar repo
2. Crear rama: `git checkout -b feature/my-feature`
3. Hacer cambios
4. Commit: `git commit -m "descripci√≥n clara"`
5. Push: `git push origin feature/my-feature`
6. Crear PR en GitHub

## Est√°ndares de C√≥digo

### Backend
- Black para formatting: `black app/`
- Ruff para linting: `ruff check app/`
- mypy para type checking: `mypy app/ --strict`

### Frontend
- ESLint: `npm run lint:fix`
- Prettier: `npm run format`
- TypeScript: `npm run typecheck`

## Testing

### Backend
- M√≠nimo 70% coverage
- Tests nombrados: `test_*_test.py`
- Patrones: `test_happy_path`, `test_error_case`

### Frontend
- E2E tests: `npm run test:e2e`
- Coverage: `npm test -- --coverage`

## Documentaci√≥n

- Actualizar `docs/` si cambias funcionalidad
- Actualizar CHANGELOG.md
- Escribir docstrings (backend)
- Escribir JSDoc (frontend)
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

#### Tarea 5.8: Commit SEMANA 5

```bash
git add -A
git commit -m "SEMANA 5: Reorganizar 606 archivos .md

Documentaci√≥n:
- Reducir ra√≠z de 239 ‚Üí 5 archivos .md
- Reorganizar docs/ en estructura clara
- Crear docs/README.md como √≠ndice
- Crear gu√≠as: desarrollo, testing
- Crear security/, troubleshooting/
- Eliminar carpeta 06-archive/ (duplicada)

Resultado:
- docs/ limpio y bien organizado
- Links verificados
- √çndice claro de navegaci√≥n
- Ra√≠z limpia

Total: 606 archivos consolidados y organizados
"

git push -u origin claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM
```

---

**üìä SEMANA 5 RESUMEN:**
- ‚è±Ô∏è Estimado: 24 horas
- ‚úÖ De 239 ‚Üí 5 archivos en ra√≠z
- ‚úÖ docs/ reorganizado y claro
- ‚úÖ √çndice de documentaci√≥n
- ‚úÖ 606 archivos organizados
- üéØ Siguiente: SEMANA 6 - Testing

---

## <a name="semana-6"></a>üß™ SEMANA 6: TESTING (Quality assurance)

**Objetivo:** +70% code coverage, CI/CD pipeline automatizado
**Estimado:** 32 horas
**Riesgo:** BAJO

### Lunes: Backend type checking con mypy

#### Tarea 6.1: Configurar y ejecutar mypy

```bash
# 1. Crear/actualizar mypy.ini
cat > backend/mypy.ini << 'EOF'
[mypy]
python_version = 3.11
strict = True
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
disallow_any_generics = True
check_untyped_defs = True
no_implicit_optional = True
warn_redundant_casts = True
warn_unused_ignores = True
warn_no_return = True

[mypy-tests.*]
ignore_errors = True

[mypy-sqlalchemy.*]
ignore_missing_imports = True

[mypy-alembic.*]
ignore_missing_imports = True
EOF

# 2. Ejecutar mypy
cd backend
mypy app/ > /tmp/mypy_report.txt 2>&1

# 3. Ver errores
head -100 /tmp/mypy_report.txt
tail -20 /tmp/mypy_report.txt  # Resumen
```

**Encontrar√° errores como:**
```
error: Argument 1 to "process_data" has incompatible type "Optional[str]"; expected "str"
error: Incompatible return value type (got "None", expected "User")
```

#### Tarea 6.2: Arreglar errores de type checking

**Crear:**  `/MYPY_FIXES_LOG.md`

```markdown
# Arreglando type checking errors

## Patr√≥n 1: Optional sin checks

ANTES:
def process(data: Optional[str]):
    return data.upper()  # ‚ùå Error: Optional

DESPU√âS:
def process(data: Optional[str]):
    if data is None:
        raise ValueError("data cannot be None")
    return data.upper()  # ‚úÖ OK
```

**Arreglar todos los Optional[T] sin protecci√≥n:**
```bash
# 1. Encontrar patrones
grep -r "Optional\[" backend/app/ --include="*.py" | grep -v "if.*is None\|or\|assert" > /tmp/optional_issues.txt

# 2. Para cada uno, agregar validaci√≥n
# 3. Ejecutar mypy de nuevo
mypy backend/app/ | grep "Optional"
# Debe disminuir el n√∫mero de errores
```

**Tiempo:** 4 horas
**Prioridad:** üü† ALTA

---

#### Tarea 6.3: CI/CD pipeline para mypy

**Crear:** `.github/workflows/mypy.yml`

```yaml
name: Type Checking

on: [push, pull_request]

jobs:
  mypy:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: pip install -r backend/requirements.txt
      - run: cd backend && mypy app/ --strict
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

### Martes-Mi√©rcoles: Frontend unit tests

#### Tarea 6.4: Crear vitest.config.ts

**Crear:** `frontend/vitest.config.ts`

```typescript
import { defineConfig } from 'vitest/config'
import react from '@vitejs/plugin-react'
import path from 'path'

export default defineConfig({
  plugins: [react()],
  test: {
    globals: true,
    environment: 'jsdom',
    setupFiles: './tests/setup.ts',
    coverage: {
      provider: 'v8',
      reporter: ['text', 'html', 'lcov'],
      include: ['**/*.{ts,tsx}'],
      exclude: [
        'node_modules/',
        'dist/',
        '**/*.d.ts',
        '**/*.stories.tsx',
      ],
      lines: 70,  // Target: 70% coverage
      functions: 70,
      branches: 65,
      statements: 70,
    },
  },
  resolve: {
    alias: {
      '@': path.resolve(__dirname, './'),
    },
  },
})
```

**Crear:** `frontend/tests/setup.ts`

```typescript
import '@testing-library/jest-dom'
import { expect, afterEach } from 'vitest'
import { cleanup } from '@testing-library/react'

afterEach(() => {
  cleanup()
})
```

**Tiempo:** 1 hora
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 6.5: Escribir 10 test files

**Crear:** `frontend/tests/components/...`

```typescript
// tests/components/header.test.tsx
import { describe, it, expect } from 'vitest'
import { render, screen } from '@testing-library/react'
import Header from '@/components/header'

describe('Header Component', () => {
  it('renders navigation links', () => {
    render(<Header />)
    expect(screen.getByText('Candidates')).toBeInTheDocument()
    expect(screen.getByText('Employees')).toBeInTheDocument()
  })

  it('shows user profile button when authenticated', () => {
    render(<Header />)
    expect(screen.getByRole('button', { name: /profile/i })).toBeInTheDocument()
  })
})
```

**Crear tests m√≠nimos para:**
1. Header component
2. Login form
3. Dashboard layout
4. API client (lib/api.ts)
5. Authentication hooks
6. Form validation
7. Table component
8. Modal component
9. Theme provider
10. Router setup

**Tiempo:** 12 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 6.6: Ejecutar y validar cobertura

```bash
npm test -- --coverage

# Resultado esperado:
# ‚úì File            | % Stmts | % Branch | % Funcs | % Lines | Uncovered Lines
# ‚úì All files       |    73.2 |     68.5 |    75.8 |    73.2 |
```

**Tiempo:** 2 horas
**Prioridad:** üü† ALTA

---

### Jueves: Backend pytest improvements

#### Tarea 6.7: Aumentar cobertura pytest

```bash
cd backend

# Ver cobertura actual
pytest tests/ --cov=app --cov-report=term-missing | grep "TOTAL"

# Escribir tests para archivos con baja cobertura
# Crear: tests/test_housing.py
# Crear: tests/test_apartments_v2.py
# Crear: tests/test_ai_agents.py

# Ejecutar nuevamente
pytest tests/ --cov=app --cov-report=html
# Abirir: htmlcov/index.html
```

**Target:** >70% coverage

**Tiempo:** 4 horas
**Prioridad:** üü° MEDIA

---

#### Tarea 6.8: CI/CD pipeline para tests

**Crear:** `.github/workflows/test.yml`

```yaml
name: Testing

on: [push, pull_request]

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_DB: uns_claudejp_test
          POSTGRES_PASSWORD: test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - run: |
          pip install -r backend/requirements.txt
          cd backend && pytest tests/ -v --cov=app

  frontend-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 20
      - run: |
          npm ci
          npm run typecheck
          npm run lint
          npm test -- --coverage

  e2e-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 20
      - run: |
          npm ci
          npm run test:e2e
```

**Tiempo:** 2 horas
**Prioridad:** üü° MEDIA

---

### Viernes: Linting y validaci√≥n

#### Tarea 6.9: ESLint + Prettier (Frontend)

```bash
cd frontend

# Ejecutar linting
npm run lint

# Arreglar
npm run lint:fix

# Formatting
npm run format

# Type checking
npm run typecheck
```

**Crear:** `.github/workflows/lint.yml`

```yaml
name: Linting

on: [push, pull_request]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: 20
      - run: npm ci && npm run lint && npm run typecheck
```

**Tiempo:** 2 horas
**Prioridad:** üü° MEDIA

---

#### Tarea 6.10: Commit SEMANA 6

```bash
git add -A
git commit -m "SEMANA 6: Agregar testing y type checking

Backend:
- Configurar mypy strict mode
- Arreglar 100+ type errors
- Coverage pytest > 70%
- CI/CD pipeline mypy

Frontend:
- Crear vitest.config.ts
- Escribir 10 test files
- Unit tests para componentes cr√≠ticos
- Coverage > 70%
- CI/CD pipeline tests

Quality:
- ESLint + Prettier configurados
- TypeScript strict mode
- CI/CD autom√°tico en cada push
- Coverage reports (HTML)

Validado: ‚úÖ 70% coverage, ‚úÖ CI/CD working, ‚úÖ No type errors
"

git push -u origin claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM
```

---

**üìä SEMANA 6 RESUMEN:**
- ‚è±Ô∏è Estimado: 32 horas
- ‚úÖ mypy + type checking en backend
- ‚úÖ 10 test files frontend (70% coverage)
- ‚úÖ pytest backend (70% coverage)
- ‚úÖ CI/CD pipeline automatizado
- üéØ Siguiente: SEMANA 7 - Performance

---

## <a name="semana-7"></a>‚ö° SEMANA 7: PERFORMANCE (Optimization & Security)

**Objetivo:** Optimizar y asegurar sistema
**Estimado:** 24 horas
**Riesgo:** BAJO

### Lunes: Security audit

#### Tarea 7.1: Revisar secrets y credenciales

```bash
# 1. Buscar secrets en el c√≥digo
cd /home/user/UNS-ClaudeJP-6.0.0
grep -r "password\|secret\|api_key\|token" . \
  --include="*.py" --include="*.ts" --include="*.tsx" \
  --exclude-dir=node_modules --exclude-dir=.git | \
  grep -v "^Binary" | \
  head -50

# 2. Verificar .env.example no tiene valores reales
cat backend/.env.example | grep -E "=\w+@\w+\.\w+|=\d{20,}|=sk_live_|=pk_live_"
# Debe estar vac√≠o

# 3. Verificar .env no est√° en git
git status | grep ".env"
# Debe estar en .gitignore
```

**Crear:** `docs/security/secrets.md`

```markdown
# Manejo de Secrets y Credenciales

## Valores Sensibles

NUNCA commitear:
- .env (credenciales reales)
- API keys (Azure, Gemini, etc.)
- JWT secrets
- Database passwords
- Tokens

## Variables de Entorno

Usar .env.example como template:
1. Copiar: `cp .env.example .env`
2. Completar con valores reales
3. NUNCA commitear .env
4. git status debe ignorarlo

## Rotaci√≥n de Secrets

Cada 30 d√≠as:
- [ ] Cambiar SECRET_KEY en backend
- [ ] Rotar API keys
- [ ] Cambiar admin password

## En Producci√≥n

- Usar CI/CD secrets
- Variables de entorno en host
- Never log sensitive data
- Use secrets vault (Vault, AWS Secrets Manager)
```

**Tiempo:** 2 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 7.2: CORS y Network Security

**Revisar:** `backend/app/core/config.py`

```python
# Verificar CORS origins
BACKEND_CORS_ORIGINS = [
    "http://localhost:3000",  # Dev OK
    "http://127.0.0.1:3000",  # Dev OK
    # En producci√≥n: agregar dominio real
    # "https://app.mycompany.com"
]

# En producci√≥n, NO incluir localhost
```

**Crear:** `docs/security/cors.md`

```markdown
# CORS Configuration

## Desarrollo

Se permite localhost:3000

## Producci√≥n

Cambiar a dominio real:
```python
BACKEND_CORS_ORIGINS = [
    "https://app.mycompany.com",
]
```

NO permitir:
- http:// en producci√≥n
- localhost
- Dominios wildcard (*)
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

### Martes: Performance optimization

#### Tarea 7.3: An√°lisis de queries lentas

```bash
# 1. Habilitar query logging
docker exec uns-claudejp-db psql -U uns_admin -d uns_claudejp << 'EOF'
ALTER SYSTEM SET log_statement = 'all';
ALTER SYSTEM SET log_duration = 'on';
SELECT pg_reload_conf();
EOF

# 2. Ejecutar operaciones
curl http://localhost:8000/api/candidates
curl http://localhost:8000/api/employees
# ... m√°s calls

# 3. Ver queries lentas
docker exec uns-claudejp-db tail -100 /var/log/postgresql/postgresql.log | grep "duration"

# 4. Identificar N+1 problems
# Ejemplo: 1 query para lista + 1 por item = N+1
```

**Crear √≠ndices faltantes:**

```sql
-- Conectar a BD
docker exec -it uns-claudejp-db psql -U uns_admin -d uns_claudejp

-- Crear √≠ndices si no existen
CREATE INDEX IF NOT EXISTS idx_candidates_status ON candidates(status);
CREATE INDEX IF NOT EXISTS idx_employees_factory_id ON employees(factory_id);
CREATE INDEX IF NOT EXISTS idx_timer_cards_employee_id ON timer_cards(employee_id);
CREATE INDEX IF NOT EXISTS idx_payroll_employee_id ON payroll(employee_id);

-- Verificar
SELECT indexname FROM pg_indexes WHERE tablename = 'candidates';
```

**Tiempo:** 3 horas
**Prioridad:** üü° MEDIA

---

#### Tarea 7.4: Frontend bundle analysis

```bash
cd frontend

# Instalar webpack-bundle-analyzer
npm install --save-dev webpack-bundle-analyzer

# Analizar bundle
npm run build
npx webpack-bundle-analyzer .next/static/chunks

# Identificar dependencias grandes
# Eliminar si no se usan
```

**Crear:** `docs/guides/performance.md`

```markdown
# Performance Tuning

## Backend

- Usar query select espec√≠fico (no *)
- Implementar pagination (limit 100)
- Agregar caching en endpoints frecuentes
- Connection pooling en BD

## Frontend

- Lazy load componentes
- Tree-shake dependencias no usadas
- Compress images
- Minify CSS/JS (Next.js lo hace auto)

## Cache

- Redis para sesiones
- CDN para assets est√°ticos
- Browser cache para im√°genes
```

**Tiempo:** 2 horas
**Prioridad:** üü° MEDIA

---

### Mi√©rcoles-Jueves: Monitoring

#### Tarea 7.5: Agregar observabilidad

**Ya existe:** OpenTelemetry + Prometheus + Grafana

```bash
# Verificar servicios
docker compose ps | grep -E "prometheus|grafana|tempo|otel"

# Acceder a Grafana
curl http://localhost:3001  # Admin/admin

# Ver dashboards pre-configured
# - Backend metrics
# - Request latency
# - Error rates
```

**Crear:** `docs/guides/monitoring.md`

```markdown
# Monitoring & Observability

## Prometheus

Acceder a: http://localhost:9090

Queries √∫tiles:
- `rate(http_requests_total[5m])` - Request rate
- `histogram_quantile(0.99, http_request_duration)` - P99 latency
- `increase(errors_total[1h])` - Error count

## Grafana

Acceder a: http://localhost:3001

Pre-configured dashboards:
- Backend Metrics
- Request Latency
- Error Tracking

## Alerting

Configurar alertas para:
- Error rate > 1%
- P99 latency > 1s
- Database connection errors
```

**Tiempo:** 2 horas
**Prioridad:** üü° MEDIA

---

#### Tarea 7.6: Health checks y readiness probes

**Verificar:** `backend/app/api/monitoring.py`

```python
@router.get("/health", tags=["monitoring"])
async def health_check():
    """Health check para load balancer"""
    return {
        "status": "healthy",
        "version": APP_VERSION,
        "timestamp": datetime.now()
    }

@router.get("/ready", tags=["monitoring"])
async def readiness_check():
    """Readiness check (puede servir requests?)"""
    # Verificar conexi√≥n a BD
    # Verificar Redis
    # Verificar dependencias
    return {"ready": True}
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

### Viernes: Documentaci√≥n y commit

#### Tarea 7.7: Crear runbooks

**Crear:** `docs/guides/runbooks.md`

```markdown
# Runbooks (Gu√≠as de Operaci√≥n)

## Incident Response

### High Error Rate (>5%)

1. Revisar logs: `docker compose logs backend | grep ERROR`
2. Verificar BD: `docker compose logs db`
3. Revisar Prometheus: http://localhost:9090
4. Si es DB: Aumentar conexiones, reiniciar
5. Si es c√≥digo: Rollback a versi√≥n anterior

### High Latency (>2s)

1. Analizar queries: Logs de PostgreSQL
2. Revisar √≠ndices: `SELECT * FROM pg_stat_user_tables`
3. Aumentar cache
4. Verificar recursos: CPU, RAM

## Maintenance Windows

Cada mes:
- [ ] Backup BD completo
- [ ] Analizar VACUUM
- [ ] Rotar logs
- [ ] Update dependencies
```

**Tiempo:** 2 horas
**Prioridad:** üü° MEDIA

---

#### Tarea 7.8: Commit SEMANA 7

```bash
git add -A
git commit -m "SEMANA 7: Security & Performance

Security:
- Auditor√≠a de secrets y credenciales
- CORS configuration documentado
- .env nunca en git
- JWT rotation guide

Performance:
- Queries optimizadas (√≠ndices creados)
- Bundle size an√°lisis
- Caching implementado
- Health checks configurados

Monitoring:
- OpenTelemetry working
- Prometheus + Grafana conectados
- Alertas configuradas
- Runbooks de operaci√≥n

Documentaci√≥n:
- security/secrets.md
- security/cors.md
- guides/performance.md
- guides/monitoring.md
- guides/runbooks.md

Validado: ‚úÖ Security audit passed, ‚úÖ Performance OK, ‚úÖ Monitoring working
"

git push -u origin claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM
```

---

**üìä SEMANA 7 RESUMEN:**
- ‚è±Ô∏è Estimado: 24 horas
- ‚úÖ Security audit completado
- ‚úÖ Performance optimizado
- ‚úÖ Monitoring configurado
- ‚úÖ Runbooks de operaci√≥n
- üéØ Siguiente: SEMANA 8 - QA Final

---

## <a name="semana-8"></a>üéØ SEMANA 8: QA FINAL y RELEASE v6.0.0

**Objetivo:** Validar 100%, listo para producci√≥n
**Estimado:** 20 horas
**Riesgo:** BAJO

### Lunes-Martes: Testing integral

#### Tarea 8.1: Correr suite COMPLETA de tests

```bash
# 1. Backend tests
cd backend
pytest tests/ -v --tb=short --cov=app --cov-report=html

# 2. Frontend tests
cd frontend
npm test -- --coverage

# 3. E2E tests
npm run test:e2e

# 4. Type checking
npm run typecheck
mypy app/ --strict

# 5. Linting
npm run lint
cd ../backend && pylint app/ --disable=all --enable=E,F
```

**Resultado esperado:**
```
‚úÖ Backend tests: PASSED (48/48)
‚úÖ Frontend tests: PASSED (10/10)
‚úÖ E2E tests: PASSED (16/16)
‚úÖ Type checking: 0 errors
‚úÖ Coverage: >70%
```

**Tiempo:** 4 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 8.2: Manual testing de flujos cr√≠ticos

**Crear:** `TESTING_CHECKLIST.md`

```markdown
# Manual Testing Checklist

## Login y Autenticaci√≥n
- [ ] Admin login (admin/admin123)
- [ ] JWT token generado
- [ ] Token refresh funciona
- [ ] Logout limpia sesi√≥n
- [ ] 401 sin token
- [ ] 403 sin permisos

## Candidatos (Rirekisho)
- [ ] Crear candidato
- [ ] Subir foto/CV
- [ ] OCR procesa imagen
- [ ] Editar candidato
- [ ] Listar con filtros
- [ ] Exportar a Excel
- [ ] Eliminar (soft delete)

## Empleados
- [ ] Crear empleado
- [ ] Asignar a factory
- [ ] Editar datos
- [ ] Listar con filtros
- [ ] Desactivar empleado

## N√≥mina
- [ ] Crear per√≠odo
- [ ] Calcular n√≥mina
- [ ] Generar recibo
- [ ] Exportar PDF
- [ ] Historial de pagos

## Timer Cards
- [ ] Registrar entrada/salida
- [ ] Calcular horas
- [ ] Reportar por empleado
- [ ] Reportar por mes

## Vivienda
- [ ] Listar apartamentos
- [ ] Asignar empleado
- [ ] Calcular alquiler
- [ ] Reportar deudas

## Requests (Solicitudes)
- [ ] Crear request
- [ ] Workflow de aprobaci√≥n
- [ ] Notificaciones

## Admin
- [ ] Crear usuario
- [ ] Cambiar rol
- [ ] Ver audit log
- [ ] Exportar datos
```

Ejecutar cada uno:
```bash
# 1. Acceder a http://localhost:3000
# 2. Seguir checklist
# 3. Documentar cualquier issue
```

**Tiempo:** 6 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 8.3: Instalaci√≥n limpia en ambiente nuevo

```bash
# 1. Crear VM nueva O limpiar Docker
docker compose down -v
rm .env
rm -rf postgres_data/

# 2. Clone repo fresh
cd /tmp
git clone https://github.com/jokken79/UNS-ClaudeJP-6.0.0.git
cd UNS-ClaudeJP-6.0.0

# 3. Seguir INSTALACION_RAPIDA.md
python scripts/setup/generate_env.py
docker compose up -d
sleep 30

# 4. Validar
curl http://localhost:8000/api/health
curl http://localhost:3000

# 5. Login
# Usuario: admin
# Contrase√±a: admin123

# 6. Verificar flujos
# - Crear candidato
# - Crear empleado
# - Ver n√≥mina
```

**Tiempo:** 2 horas
**Prioridad:** üî¥ CR√çTICA

---

### Mi√©rcoles: Release preparation

#### Tarea 8.4: Actualizar versi√≥n en TODA documentaci√≥n

```bash
# 1. Buscar referencias a v5.6.0 o v6.0.0-rc
grep -r "5\.6\|6\.0\.0-\|beta\|alpha\|rc" . \
  --include="*.md" --include="*.py" --include="*.json" \
  --exclude-dir=.git --exclude-dir=node_modules

# 2. Actualizar a v6.0.0 final
# En README.md, CLAUDE.md, package.json, pyproject.toml

# 3. Verificar badges
grep "6\.0\.0" README.md
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

#### Tarea 8.5: Crear RELEASE_NOTES_V6.0.0.md

```markdown
# Release Notes v6.0.0

## üéâ Hitos Alcanzados

### üîß Instalaci√≥n
- ‚úÖ Sistema instala desde cero sin errores
- ‚úÖ Docker Compose completamente funcional
- ‚úÖ Migraciones aplicadas correctamente
- ‚úÖ Data seed autom√°tico

### üßπ Limpieza de C√≥digo
- ‚úÖ De 305 ‚Üí 210 archivos Python (-31%)
- ‚úÖ De 98,854 ‚Üí 70,000 l√≠neas (-29%)
- ‚úÖ 96 scripts consolidados ‚Üí 12 esenciales
- ‚úÖ 38 servicios consolidados ‚Üí 20
- ‚úÖ 7 directorios orphaned eliminados

### üìö Documentaci√≥n
- ‚úÖ 606 archivos .md organizados
- ‚úÖ Ra√≠z limpia (5 archivos)
- ‚úÖ docs/ bien estructurado
- ‚úÖ Gu√≠as de desarrollo, testing, deployment

### üß™ Testing
- ‚úÖ Backend: >70% coverage (pytest)
- ‚úÖ Frontend: >70% coverage (vitest)
- ‚úÖ E2E: 16 tests (Playwright)
- ‚úÖ Type checking: 0 mypy errors
- ‚úÖ CI/CD automatizado

### ‚ö° Performance
- ‚úÖ Queries optimizadas
- ‚úÖ √çndices de BD creados
- ‚úÖ Bundle size optimizado
- ‚úÖ Caching implementado
- ‚úÖ Monitoring (Prometheus + Grafana)

### üîê Security
- ‚úÖ Secrets audit completado
- ‚úÖ CORS configurado correctamente
- ‚úÖ JWT rotation documentado
- ‚úÖ Health checks implementados

## üöÄ C√≥mo Actualizar

### Desde v5.6.0

```bash
git pull origin main
python scripts/setup/generate_env.py
docker compose down -v
docker compose up -d
docker compose exec backend bash -c "cd /app && alembic upgrade head"
```

## üìã Conocido Issues

- None (v6.0.0 es stable)

## üìñ Documentaci√≥n

- [Instalaci√≥n R√°pida](INSTALACION_RAPIDA.md)
- [Gu√≠a de Desarrollo](docs/guides/desarrollo.md)
- [Troubleshooting](docs/troubleshooting/common-errors.md)

## üôè Gracias

v6.0.0 incluye 8 semanas de refactoring y cleanup. El sistema ahora es:
- 30% m√°s mantenible (menos c√≥digo muerto)
- 70%+ testeado (coverage)
- 100% type-safe (mypy strict)
- Listo para producci√≥n
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

#### Tarea 8.6: Crear DEPLOYMENT_CHECKLIST.md

```markdown
# Deployment Checklist v6.0.0

## Pre-deployment (24h antes)

- [ ] Backup completo de BD
- [ ] Revisar logs (√∫ltimas 24h)
- [ ] Verificar alertas en Prometheus
- [ ] Revisar PRs pendientes

## Validaci√≥n Final

- [ ] Todos tests PASSING
- [ ] Coverage > 70%
- [ ] Instalaci√≥n limpia funciona
- [ ] Manual testing completado
- [ ] Security audit passed
- [ ] Performance benchmarks OK

## Deployment

1. [ ] Tag git: `git tag v6.0.0`
2. [ ] Push tag: `git push origin v6.0.0`
3. [ ] Crear release en GitHub
4. [ ] Generar changelog autom√°tico
5. [ ] Notificar stakeholders

## Post-deployment (1h despu√©s)

- [ ] Verificar sistema en vivo
- [ ] Monitorear logs/errors
- [ ] Check Prometheus metrics
- [ ] Verificar que usuarios pueden loguear
- [ ] Prueba flujo cr√≠tico (crear candidato)
- [ ] Verificar notificaciones funcionan

## Rollback Plan

Si algo falla:
```bash
git revert v6.0.0
docker compose down
git checkout v5.6.0
docker compose up -d
docker compose exec backend bash -c "cd /app && alembic downgrade -1"
```

## Handoff

- [ ] Documentar cualquier issue encontrado
- [ ] Crear tickets para problemas menores
- [ ] Training a team
```

**Tiempo:** 1 hora
**Prioridad:** üü° MEDIA

---

### Jueves-Viernes: Final QA y commit

#### Tarea 8.7: √öltima validaci√≥n (Final audit)

```bash
# 1. Verificar que TODO est√° en repo
git status
# Debe mostrar "working tree clean"

# 2. √öltimo test run
cd backend && pytest tests/ -v
cd ../frontend && npm test -- --coverage

# 3. √öltimo E2E
npm run test:e2e

# 4. Build
npm run build  # Frontend
# Backend ya est√° en Docker

# 5. Verificar archivos importantes existen
[ -f README.md ] && echo "‚úÖ README.md"
[ -f CLAUDE.md ] && echo "‚úÖ CLAUDE.md"
[ -f CHANGELOG_V6.0.0.md ] && echo "‚úÖ CHANGELOG"
[ -f INSTALACION_RAPIDA.md ] && echo "‚úÖ INSTALACION"
[ -f docs/README.md ] && echo "‚úÖ docs/README.md"
[ -f backend/requirements.txt ] && echo "‚úÖ requirements.txt"
[ -f frontend/package.json ] && echo "‚úÖ package.json"
```

**Tiempo:** 2 horas
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 8.8: Commit final y tag de release

```bash
git add -A
git commit -m "SEMANA 8: QA Final y Release v6.0.0

Validaci√≥n:
- ‚úÖ Suite completa de tests PASSING
- ‚úÖ 70%+ coverage (backend + frontend)
- ‚úÖ Manual testing de todos flujos
- ‚úÖ Instalaci√≥n limpia funciona 100%
- ‚úÖ Security audit completado
- ‚úÖ Performance benchmarks OK
- ‚úÖ Type checking: 0 errors

Documentaci√≥n:
- Release notes completos
- Deployment checklist
- Runbooks de operaci√≥n
- Guides de desarrollo

Sistema LISTO PARA PRODUCCI√ìN.

Resultado de 8 semanas:
- 31% reducci√≥n de c√≥digo (de 305 ‚Üí 210 archivos)
- 29% reducci√≥n de l√≠neas (98,854 ‚Üí 70,000)
- 70%+ test coverage
- 0 type errors (mypy strict)
- Documentaci√≥n organizada y clara
- CI/CD automatizado
- Security & Performance audited

v6.0.0 es STABLE y PRODUCTION-READY ‚úÖ
"

git tag -a v6.0.0 -m "Release v6.0.0 - Production Ready

8 weeks of refactoring, testing, and cleanup.
System is now maintainable, scalable, and well-documented."

git push -u origin claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM
git push origin v6.0.0
```

**Tiempo:** 15 min
**Prioridad:** üî¥ CR√çTICA

---

#### Tarea 8.9: Crear PR final para merge a main

```bash
# En GitHub, crear PR:
# Title: "Release v6.0.0 - Production Ready"
# Description: Copiar release notes
# Base: main
# Compare: claude/project-audit-cleanup-01BnhrSyZcJhG4EA3hg4tCyM

# Pasos en GitHub:
# 1. Create Pull Request
# 2. Esperar checks pasen (CI/CD)
# 3. Review final
# 4. Merge
# 5. Crear Release desde tag v6.0.0
```

**Tiempo:** 30 min
**Prioridad:** üü° MEDIA

---

**üìä SEMANA 8 RESUMEN:**
- ‚è±Ô∏è Estimado: 20 horas
- ‚úÖ Suite completa tests PASSING
- ‚úÖ 70%+ coverage
- ‚úÖ Instalaci√≥n limpia validada
- ‚úÖ Manual testing completado
- ‚úÖ Release notes y deployment checklist
- ‚úÖ Tag v6.0.0 creado
- üéâ LISTO PARA PRODUCCI√ìN

---

## <a name="checkpoints"></a>‚úÖ CHECKPOINTS DE VALIDACI√ìN

### Checkpoint SEMANA 1
```
[ ] docker compose up -d ‚Üí sin errores
[ ] curl http://localhost:8000/api/health ‚Üí 200 OK
[ ] Login funciona
[ ] README.md v6.0.0
[ ] CHANGELOG_V6.0.0.md existe
[ ] INSTALACION_RAPIDA.md existe
```

### Checkpoint SEMANA 2
```
[ ] alembic upgrade head ‚Üí success
[ ] Schema BD matches models.py
[ ] pytest tests/ ‚Üí PASS
[ ] API funciona
[ ] Datos persistieron
```

### Checkpoint SEMANA 3-4
```
[ ] De 305 ‚Üí 210 archivos Python
[ ] De 96 ‚Üí 12 scripts
[ ] De 38 ‚Üí 20 servicios
[ ] pytest tests/ ‚Üí PASS
[ ] API funciona normalmente
```

### Checkpoint SEMANA 5
```
[ ] Ra√≠z: 239 ‚Üí 5 archivos .md
[ ] docs/ reorganizado
[ ] docs/README.md existe
[ ] Links verificados
[ ] 0 archivos duplicados
```

### Checkpoint SEMANA 6
```
[ ] mypy: 0 type errors
[ ] pytest: >70% coverage
[ ] npm test: >70% coverage
[ ] CI/CD pipelines activos
[ ] ESLint / Prettier configurados
```

### Checkpoint SEMANA 7
```
[ ] Security audit completado
[ ] Performance optimizado
[ ] √çndices de BD creados
[ ] Monitoring funcionando
[ ] Runbooks documentados
```

### Checkpoint SEMANA 8
```
[ ] Todos tests PASSING
[ ] Instalaci√≥n limpia funciona 100%
[ ] Manual testing completado
[ ] Release notes completos
[ ] Tag v6.0.0 creado
[ ] PR listofor merge
```

---

## üìä RESUMEN FINAL: TRANSFORMACI√ìN v6.0.0

```
M√âTRICA                    ANTES      DESPU√âS    MEJORA
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Archivos Python            305        210        -31%
L√≠neas de c√≥digo           98,854     70,000     -29%
Scripts                    96         12         -87%
Servicios                  38         20         -47%
Archivos .md              606         ~100       -83%
Test coverage             ~40%       >70%       +75%
Type errors               100+        0          100%
Documentaci√≥n (calidad)    4/10       9/10       +125%
Mantenibilidad            5/10       8/10       +60%

ESTADO FINAL:              6.5/10     9.0/10     ‚úÖ PRODUCCI√ìN READY
```

---

## üéØ CONCLUSI√ìN

**¬°Enhorabuena!** Has completado 8 semanas de transformaci√≥n exhaustiva.

El sistema UNS-ClaudeJP v6.0.0 ahora es:
- ‚úÖ **Mantenible** - 30% menos c√≥digo, arquitectura clara
- ‚úÖ **Confiable** - 70%+ tested, 0 type errors
- ‚úÖ **Documentado** - Gu√≠as claras, ejemplos
- ‚úÖ **Seguro** - Audit completado, secrets management
- ‚úÖ **Performante** - Queries optimizadas, caching, √≠ndices
- ‚úÖ **Listo para producci√≥n** - Deployment checklist, monitoring

### Pr√≥ximos pasos:
1. **Deploy a producci√≥n**
2. **Monitorear por 1 semana**
3. **Documentar issues encontrados**
4. **Planificar v6.1.0** (mejoras menores)

**Est√°s listo. ¬°A producci√≥n! üöÄ**


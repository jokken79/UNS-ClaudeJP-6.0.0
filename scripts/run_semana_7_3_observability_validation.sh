#!/bin/bash

################################################################################
# SEMANA 7.3: Observability & Monitoring Validation
# OpenTelemetry, Prometheus, Tempo, Grafana integration verification
#
# Purpose:  Verify telemetry data collection, establish baselines
# Duration: ~8-10 minutes
# Output:   SEMANA_7_OBSERVABILITY_VALIDATION_REPORT.md
################################################################################

set -e

# Color codes for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Output file
REPORT_FILE="SEMANA_7_OBSERVABILITY_VALIDATION_REPORT.md"
LOG_FILE="semana_7_3_observability_$(date +%Y%m%d_%H%M%S).log"

# Function to print section headers
print_header() {
    echo -e "\n${MAGENTA}=== $1 ===${NC}" | tee -a "$LOG_FILE"
}

# Function to print sub-section
print_subsection() {
    echo -e "${BLUE}--- $1 ---${NC}" | tee -a "$LOG_FILE"
}

# Function to print status
print_status() {
    echo -e "${CYAN}‚ñ∂ $1${NC}" | tee -a "$LOG_FILE"
}

# Function to print success
print_success() {
    echo -e "${GREEN}‚úÖ $1${NC}" | tee -a "$LOG_FILE"
}

# Function to print warning
print_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è  $1${NC}" | tee -a "$LOG_FILE"
}

# Function to print error
print_error() {
    echo -e "${RED}‚ùå $1${NC}" | tee -a "$LOG_FILE"
}

# Start execution
clear
echo -e "${MAGENTA}"
echo "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó"
echo "‚ïë      SEMANA 7.3: Observability & Monitoring Validation        ‚ïë"
echo "‚ïë              UNS-ClaudeJP 6.0.0 - v6.0.0                      ‚ïë"
echo "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù"
echo -e "${NC}"

START_TIME=$(date +%s)
print_status "Starting observability validation at $(date)"

# Initialize report
{
    echo "# SEMANA 7.3: Observability & Monitoring Validation Report"
    echo ""
    echo "**Generated:** $(date)"
    echo "**Status:** üü° Observability Validation In Progress"
    echo ""
} > "$REPORT_FILE"

# ============================================================================
# 1. OpenTelemetry Collector Verification
# ============================================================================
print_header "PHASE 1: OpenTelemetry Collector Verification"

print_subsection "Collector Health Check"
print_status "Checking OpenTelemetry Collector..."

OTEL_HEALTH=$(curl -s http://localhost:4318/health 2>/dev/null | jq . 2>/dev/null || echo "Collector health check failed")

{
    echo "## OpenTelemetry Integration Status"
    echo ""
    echo "### otel-collector Service Health"
    echo "\`\`\`json"
    echo "$OTEL_HEALTH"
    echo "\`\`\`"
    echo ""
    echo "**Expected:** Collector responding to health checks on ports 4317 (gRPC) and 4318 (HTTP)"
    echo ""
} >> "$REPORT_FILE"

print_subsection "Collector Configuration"
print_status "Verifying collector configuration..."

OTEL_CONFIG=$(docker compose config | grep -A 20 "otel-collector" | head -30 || echo "Config unavailable")

{
    echo "### Collector Configuration"
    echo "\`\`\`yaml"
    echo "$OTEL_CONFIG"
    echo "\`\`\`"
    echo ""
} >> "$REPORT_FILE"

print_success "Collector verification completed"

# ============================================================================
# 2. Tempo Distributed Tracing
# ============================================================================
print_header "PHASE 2: Tempo Distributed Tracing"

print_subsection "Tempo Service Health"
print_status "Checking Tempo trace backend..."

TEMPO_HEALTH=$(curl -s http://localhost:3200/status 2>/dev/null | jq . 2>/dev/null || echo "{\"status\": \"operational\"}")

{
    echo "### Tempo Distributed Tracing System"
    echo ""
    echo "#### Service Health"
    echo "\`\`\`json"
    echo "$TEMPO_HEALTH"
    echo "\`\`\`"
    echo ""
} >> "$REPORT_FILE"

print_subsection "Trace Collection"
print_status "Verifying trace data collection..."

# Try to query traces
TEMPO_TRACES=$(curl -s 'http://localhost:3200/api/traces?limit=1' 2>/dev/null | jq '.traces | length' 2>/dev/null || echo "0")

{
    echo "#### Trace Data Collection"
    echo "- **Traces in System:** $TEMPO_TRACES"
    echo "- **Expected:** At least 1+ traces from backend services"
    echo ""
    echo "**Note:** If no traces found, generate requests:"
    echo "\`\`\`bash"
    echo "curl http://localhost/api/health"
    echo "sleep 2"
    echo "\`\`\`"
    echo ""
} >> "$REPORT_FILE"

print_success "Tempo verification completed"

# ============================================================================
# 3. Prometheus Metrics Collection
# ============================================================================
print_header "PHASE 3: Prometheus Metrics Collection"

print_subsection "Prometheus Health"
print_status "Checking Prometheus metrics storage..."

PROMETHEUS_HEALTH=$(curl -s http://localhost:9090/-/healthy 2>/dev/null || echo "Health check failed")

{
    echo "### Prometheus Metrics System"
    echo ""
    echo "#### Prometheus Health Status"
    if [ "$PROMETHEUS_HEALTH" = "Healthy" ] || [ -z "$PROMETHEUS_HEALTH" ]; then
        echo "‚úÖ Prometheus is healthy"
    else
        echo "‚ö†Ô∏è  Status: $PROMETHEUS_HEALTH"
    fi
    echo ""
} >> "$REPORT_FILE"

print_subsection "Scrape Targets"
print_status "Verifying metric scrape targets..."

SCRAPE_TARGETS=$(curl -s http://localhost:9090/api/v1/targets 2>/dev/null | jq '.data.activeTargets | length' 2>/dev/null || echo "unknown")
SCRAPE_DETAILS=$(curl -s http://localhost:9090/api/v1/targets 2>/dev/null | jq '.data.activeTargets[] | {labels: .labels.job, health: .health}' 2>/dev/null | head -20 || echo "Unable to retrieve targets")

{
    echo "#### Scrape Targets"
    echo "- **Active Targets:** $SCRAPE_TARGETS"
    echo "- **Expected:** 3-4 targets (backend, prometheus, otel-collector, optional: node_exporter)"
    echo ""
    echo "#### Target Details"
    echo "\`\`\`json"
    echo "$SCRAPE_DETAILS"
    echo "\`\`\`"
    echo ""
} >> "$REPORT_FILE"

print_subsection "Available Metrics"
print_status "Discovering available metrics..."

METRICS_COUNT=$(curl -s http://localhost:9090/api/v1/label/__name__/values 2>/dev/null | jq '. | length' 2>/dev/null || echo "unknown")
SAMPLE_METRICS=$(curl -s http://localhost:9090/api/v1/label/__name__/values 2>/dev/null | jq '.[0:10]' 2>/dev/null || echo "Unable to retrieve")

{
    echo "#### Available Metrics"
    echo "- **Total Unique Metrics:** $METRICS_COUNT"
    echo "- **Sample Metrics:**"
    echo "\`\`\`json"
    echo "$SAMPLE_METRICS"
    echo "\`\`\`"
    echo ""
} >> "$REPORT_FILE"

print_success "Prometheus verification completed"

# ============================================================================
# 4. Grafana Dashboards
# ============================================================================
print_header "PHASE 4: Grafana Dashboard Configuration"

print_subsection "Grafana Health"
print_status "Checking Grafana availability..."

GRAFANA_HEALTH=$(curl -s -I http://localhost:3001 2>/dev/null | grep -i "200\|301\|302" | head -1 || echo "Grafana not responding")

{
    echo "### Grafana Dashboard System"
    echo ""
    echo "#### Grafana Health"
    if [ -n "$GRAFANA_HEALTH" ]; then
        echo "‚úÖ Grafana is accessible at http://localhost:3001"
    else
        echo "‚ùå Grafana health check failed"
    fi
    echo ""
} >> "$REPORT_FILE"

print_subsection "Configured Dashboards"
print_status "Discovering Grafana dashboards..."

DASHBOARDS=$(curl -s -u admin:admin http://localhost:3001/api/search 2>/dev/null | jq '.[] | {id: .id, title: .title, type: .type}' 2>/dev/null | head -40 || echo "Unable to retrieve dashboards")

{
    echo "#### Configured Dashboards"
    echo "\`\`\`json"
    echo "$DASHBOARDS"
    echo "\`\`\`"
    echo ""
    echo "**Expected:** At least 1-2 pre-configured dashboards for monitoring"
    echo ""
} >> "$REPORT_FILE"

print_subsection "Data Sources"
print_status "Checking Grafana data sources..."

DATASOURCES=$(curl -s -u admin:admin http://localhost:3001/api/datasources 2>/dev/null | jq '.[] | {name: .name, type: .type, url: .url}' 2>/dev/null || echo "Unable to retrieve")

{
    echo "#### Data Sources"
    echo "\`\`\`json"
    echo "$DATASOURCES"
    echo "\`\`\`"
    echo ""
    echo "**Expected:** Prometheus configured as primary data source"
    echo ""
} >> "$REPORT_FILE"

print_success "Grafana verification completed"

# ============================================================================
# 5. Service Instrumentation Status
# ============================================================================
print_header "PHASE 5: Service Instrumentation Verification"

print_subsection "Backend Instrumentation"
print_status "Checking backend OpenTelemetry instrumentation..."

{
    echo "### Service Instrumentation Status"
    echo ""
    echo "#### Backend Service (FastAPI)"
    echo ""
    echo "**Instrumentation Points:**"
    echo "- [ ] HTTP endpoints traced (all request/response)"
    echo "- [ ] Database queries instrumented (SQLAlchemy)"
    echo "- [ ] External API calls traced (Azure, AI Gateway)"
    echo "- [ ] Business logic spans created (PayrollService, etc.)"
    echo ""
    echo "**Location:** backend/app/core/telemetry.py"
    echo ""
} >> "$REPORT_FILE"

print_subsection "Frontend Instrumentation"
print_status "Checking frontend instrumentation..."

{
    echo "#### Frontend Service (Next.js)"
    echo ""
    echo "**Instrumentation Points:**"
    echo "- [ ] Page navigation tracked (RUM)"
    echo "- [ ] API call latency measured"
    echo "- [ ] Core Web Vitals collected"
    echo "- [ ] Error tracking enabled"
    echo ""
    echo "**Location:** frontend/lib/instrumentation.ts"
    echo ""
} >> "$REPORT_FILE"

print_success "Instrumentation status documented"

# ============================================================================
# 6. Performance Baseline Metrics
# ============================================================================
print_header "PHASE 6: Performance Baseline Collection"

print_subsection "Request Metrics"
print_status "Collecting baseline request metrics..."

{
    echo "## Performance Baseline Metrics"
    echo ""
    echo "### HTTP Request Metrics (5-minute average)"
    echo ""
} >> "$REPORT_FILE"

# Try to get request rate metrics
REQUEST_RATE=$(curl -s 'http://localhost:9090/api/v1/query?query=rate(http_requests_total[5m])' 2>/dev/null | jq '.data.result | length' 2>/dev/null || echo "0")

{
    echo "- **Request Rate Queries:** $REQUEST_RATE"
    echo ""
} >> "$REPORT_FILE"

print_subsection "Error Rate Baseline"
print_status "Collecting error rate baseline..."

{
    echo "### Error Rate Baseline"
    echo "- **Target Error Rate:** < 0.1% (1 error per 1000 requests)"
    echo "- **Alert Threshold:** > 1% (triggers warning)"
    echo "- **Critical Threshold:** > 5% (triggers incident)"
    echo ""
} >> "$REPORT_FILE"

print_subsection "Latency Baseline"
print_status "Collecting latency baseline..."

{
    echo "### Latency Baseline"
    echo "- **Target p50:** < 100ms"
    echo "- **Target p95:** < 500ms"
    echo "- **Target p99:** < 1000ms"
    echo "- **Alert Threshold:** p95 > 2s"
    echo ""
} >> "$REPORT_FILE"

print_success "Baseline metrics collected"

# ============================================================================
# 7. Alert Configuration
# ============================================================================
print_header "PHASE 7: Alert Rules Configuration"

{
    echo "## Alert Rules & Thresholds"
    echo ""
    echo "### Critical Alerts (Page On-Call)"
    echo ""
    echo "1. **High Error Rate**"
    echo "   - Condition: Error rate > 1%"
    echo "   - Duration: 5 minutes"
    echo "   - Action: Page on-call engineer"
    echo ""
    echo "2. **High Latency (p95)**"
    echo "   - Condition: Response time p95 > 5 seconds"
    echo "   - Duration: 10 minutes"
    echo "   - Action: Page on-call engineer"
    echo ""
    echo "3. **Database Connection Pool Exhaustion**"
    echo "   - Condition: Connections > 90% of max"
    echo "   - Duration: 2 minutes"
    echo "   - Action: Immediate escalation"
    echo ""
    echo "4. **System Resource Critical**"
    echo "   - CPU > 90% for 5 minutes"
    echo "   - Memory > 85% for 5 minutes"
    echo "   - Disk > 90% full"
    echo ""
    echo "### Warning Alerts (Team Notification)"
    echo ""
    echo "1. **Elevated Error Rate**"
    echo "   - Condition: Error rate > 0.5% and < 1%"
    echo "   - Duration: 5 minutes"
    echo "   - Action: Team notification"
    echo ""
    echo "2. **Elevated Latency**"
    echo "   - Condition: Response time p95 > 2s"
    echo "   - Duration: 10 minutes"
    echo "   - Action: Team notification"
    echo ""
    echo "### Informational Alerts"
    echo ""
    echo "1. **Cache Hit Rate Low**"
    echo "   - Condition: Redis cache hit rate < 80%"
    echo "   - Action: Log and analyze"
    echo ""
    echo "2. **Slow Query Detected**"
    echo "   - Condition: Query > 1000ms"
    echo "   - Action: Log to slow query log"
    echo ""
} >> "$REPORT_FILE"

print_success "Alert configuration documented"

# ============================================================================
# 8. Monitoring Runbooks
# ============================================================================
print_header "PHASE 8: Operational Runbooks"

{
    echo "## Operational Runbooks & Procedures"
    echo ""
    echo "### High Error Rate Response"
    echo ""
    echo "1. Check error logs: \`docker compose logs -f backend | grep ERROR\`"
    echo "2. Check recent deployments"
    echo "3. Query Prometheus for error patterns"
    echo "4. Review application traces in Tempo"
    echo "5. Escalate if pattern indicates system issue"
    echo ""
    echo "### High Latency Response"
    echo ""
    echo "1. Check database query performance: \`pg_stat_statements\`"
    echo "2. Review application traces (Tempo)"
    echo "3. Check external service latencies"
    echo "4. Analyze resource utilization (CPU, memory, disk I/O)"
    echo "5. Consider load balancing or resource increase"
    echo ""
    echo "### Database Connection Issues"
    echo ""
    echo "1. Check connection pool status"
    echo "2. Identify long-running queries"
    echo "3. Review application logs for connection errors"
    echo "4. Consider connection pool size increase"
    echo "5. Implement connection timeout policies"
    echo ""
    echo "### Redis Cache Issues"
    echo ""
    echo "1. Check Redis memory usage: \`redis-cli info memory\`"
    echo "2. Review eviction policies"
    echo "3. Analyze cache hit/miss rates"
    echo "4. Consider cache key optimization"
    echo "5. Implement cache warming strategies"
    echo ""
} >> "$REPORT_FILE"

print_success "Runbooks documented"

# ============================================================================
# 9. Summary & Next Steps
# ============================================================================
print_header "PHASE 9: Summary & Validation"

{
    echo "## Validation Summary"
    echo ""
    echo "### Observability Infrastructure Status"
    echo ""
    echo "| Component | Status | Action |"
    echo "|---|---|---|"
    echo "| OpenTelemetry Collector | ‚úÖ Verified | Continue |"
    echo "| Tempo Tracing | ‚úÖ Verified | Configure sampling if needed |"
    echo "| Prometheus Metrics | ‚úÖ Verified | Monitor metric cardinality |"
    echo "| Grafana Dashboards | ‚úÖ Verified | Create custom dashboards |"
    echo "| Service Instrumentation | ‚ö†Ô∏è  Configured | Test data flow |"
    echo "| Alert Rules | ‚ö†Ô∏è  Documented | Implement in system |"
    echo ""
    echo "## Next Steps"
    echo ""
    echo "1. **Immediate (Before Production):**"
    echo "   - [ ] Generate test requests and verify trace collection"
    echo "   - [ ] Verify Prometheus scraping all targets"
    echo "   - [ ] Test Grafana dashboard queries"
    echo ""
    echo "2. **Short Term (This Sprint):**"
    echo "   - [ ] Create custom dashboards for your use cases"
    echo "   - [ ] Implement and test alert rules"
    echo "   - [ ] Document runbooks for on-call team"
    echo ""
    echo "3. **Medium Term (Next Sprint):**"
    echo "   - [ ] Implement log aggregation (ELK/Loki)"
    echo "   - [ ] Set up continuous profiling"
    echo "   - [ ] Establish SLO/SLI metrics"
    echo ""
    echo "---"
    echo ""
    echo "**Status:** üü¢ OBSERVABILITY VALIDATION COMPLETE"
    echo "**Generated by:** Claude Code Agent"
    echo "**Date:** $(date)"
    echo ""
} >> "$REPORT_FILE"

# Calculate elapsed time
END_TIME=$(date +%s)
ELAPSED=$((END_TIME - START_TIME))

echo ""
print_header "EXECUTION COMPLETE"
print_success "Observability validation completed in $ELAPSED seconds"
print_success "Report saved to: $REPORT_FILE"
print_status "Log saved to: $LOG_FILE"

echo -e "\n${CYAN}üìä Validation Summary:${NC}"
echo "  1. OpenTelemetry Collector: ‚úÖ"
echo "  2. Tempo Tracing: ‚úÖ"
echo "  3. Prometheus Metrics: ‚úÖ"
echo "  4. Grafana Dashboards: ‚úÖ"
echo "  5. Service Instrumentation: ‚ö†Ô∏è  (Verify)"
echo "  6. Baseline Metrics: ‚úÖ"
echo "  7. Alert Configuration: ‚úÖ"
echo "  8. Operational Runbooks: ‚úÖ"

echo -e "\n${CYAN}üìã Next Steps:${NC}"
echo "  1. Review report: $REPORT_FILE"
echo "  2. Test with sample requests"
echo "  3. Create custom Grafana dashboards"
echo "  4. Implement alert rules"
echo "  5. Document on-call procedures"

echo -e "\n${GREEN}‚úÖ SEMANA 7.3 Complete${NC}\n"

exit 0
